{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "The baseline model is a simple sequential model with two layers. The first layer has 32 neurons with a Rectified Linear Unit (ReLU) activation function and takes input with a shape of (3,). The second layer has a single neuron, making it suitable for regression tasks, and it employs a linear activation function. \n",
    "\n",
    "\n",
    "This model is designed to predict species richness based on three input features. The architecture, particularly the number of layers, units, and activation functions, can be further adjusted depending on the specific requirements and characteristics of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Seed setting is done to remove randomness in the model training\n",
    "\n",
    "\n",
    "Based on correlation matrix analysis, following features and target variables are selected for the regression:\n",
    "\n",
    "features = 'Age', 'elevation', 'Mean_Temperature'\n",
    "\n",
    "target = 'SR_total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "#\n",
    "#Setting seed (to avoid randomness in the model convergence)\n",
    "SEED = 42\n",
    "# Set seed for NumPy\n",
    "np.random.seed(SEED)\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "# Setting Features and target variable (Age, pCO2, temp... are used to predict SR values)\n",
    "features = maxprob[['Age', 'elevation', 'Mean_Temperature']]\n",
    "target = maxprob['SR_total']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "#Normalize the data (to bring them into comparable numerical values)\n",
    "def normalize(data):\n",
    "    return (data - data.mean()) / data.std()\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Loss function used is Mean Squared Error (MSE)\n",
    "- MSE is a differentiable function, which is crucial for the optimization algorithm to\n",
    "perform gradient descent during training.\n",
    "- Minimizing MSE during training corresponds to minimizing the squared differences\n",
    "between predicted and actual values. Which is a common optimization objective in regression\n",
    "tasks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Evaluation metric used is R squared\n",
    "\n",
    "- As our primary goal is to have a model that explains and predict a certain percentage of the variance in the target variable.\n",
    "- It represents the proportion of the dependent variable's variance captured by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_baseline = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=(3,)),\n",
    "    tf.keras.layers.Dense(1)  # Output layer with one neuron for species richness prediction\n",
    "])\n",
    "\n",
    "# model compilation\n",
    "def r_squared(y_true, y_pred):\n",
    "    SS_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    SS_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    return 1 - (SS_res / (SS_tot + tf.keras.backend.epsilon()))\n",
    "\n",
    "#model_baseline.compile(optimizer='adam', loss='mean_squared_error', metrics=[r_squared])\n",
    "model_baseline.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error', metrics=[r_squared])\n",
    "\n",
    "# Train the model\n",
    "history = model_baseline.fit(X_train, y_train, epochs=40, batch_size= 32, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "# TO check & visualize if the model is overfitting\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the baseline model on test data\n",
    "loss, mae = model_baseline.evaluate(X_test, y_test, verbose=0)\n",
    "#loss, mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "#print(f'Baseline Model Test MAE: {mean_squared_error}')\n",
    "#print(f'Baseline Model Test r2: {r_squared}')\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predictions from the baseline model (already obtained)\n",
    "predictions_baseline = model_baseline.predict(X_test)\n",
    "\n",
    "# Calculate additional metrics\n",
    "mse = mean_squared_error(y_test, predictions_baseline)\n",
    "# rmse = np.sqrt(mse)\n",
    "# mae = mean_absolute_error(y_test, predictions_baseline)\n",
    "r2 = r2_score(y_test, predictions_baseline)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f' Baseline model R-squared: {r2}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
